![Cabecera](https://github.com/Periclates7/Machine_Learning_Project/blob/main/img/cabecera_repo.jpg)

# üå≥ MACHINE LEARNING PROJECT -> PREDICTING SALARIES (KAGGLE COMPETITION) üèÜ  
  
El presente proyecto nace de la inscripci√≥n a la competici√≥n de Kaggle ["Predict the Salary for Data Science Jobs"](https://www.kaggle.com/competitions/predict-salary-for-data-science-jobs/). La competici√≥n se basa en el entrenamiento de modelos de *Machine Learning* para la predicci√≥n salarios en posiciones relativas a la ciencia de datos. Para ello se cuenta con tres archivos .csv. El primero para entrenar nuestros modelos, el segundo para testearlos y el tercero nos servir√° como herramienta para competir.
  
## üéØ OBJETIVOS DEL PROYECTO 
  
1. Crear un repositorio en GitHub con una buena organizaci√≥n de los recursos.
2. Extraer los datos de manera √≥ptima.
3. Aplicar herramientas, t√©cnicas y metodolog√≠as para la limpieza de datos acordes a nuestras necesidades:
    - Filtrado de los datos extraidos
    - Exploraci√≥n del conjunto de los datos
    - Limpieza de valores nulos
    - Transformaci√≥n de diferentes conjuntos de datos
    - Librer√≠as utilizadas: Pandas, Numpy, Pylab, Seaborn, Sklearn.
3. Analizar, Adecuar y codificar los datos para ser entrenados.
4. Aplicar modelos de *Machine Learning*.
5. Evaluar dichos modelos.
6. Hacer predicciones con nuestros modelos.
7. Exportar y cargar en Kaggle nuestras predicciones.
  
## ‚õè AN√ÅLISIS Y LIMPIEZA DE LOS DATOS  
  
Nos encontramos con un *dataset* que contiene el salario de diferentes posiciones en el √°mbito de la ciencia de datos seg√∫n varias variables tales como, el tipo de empleo, la posici√≥n, el pa√≠s o su nivel de experiencia entre otras. El conjunto de datos es un conjunto muy limpio, con los datos bastante consistentes pero inoperativos ya que la mayor√≠a de las columnas son categ√≥ricas. El gran reto de este proyecto ser√° el codificar dichas columnas de la manera m√°s acertada para que nuestros modelos puedan trabajar con el m√°ximo rendimiento. 
  
Esta transformaci√≥n parte de un an√°lisis exhaustivo de las columnas a transformar. En su mayor√≠a, intento determinar la relevancia de cada dato para codificarlo en base a su importancia. Esto nos crear√° un sesgo, s√≠, pero un sesgo basado en los datos. Por otro lado tambi√©n se prueban t√©cnicas de *one-hot-encoding* para aquellas columnas que no estaban tan claramente jerarquizadas.
  
Cabe destacar que el proceso de transformaci√≥n del dato se ha visto modificado a lo largo de la realizaci√≥n del proyecto con el fin de testear cuantas m√°s posibilidades y de esta manera conseguir el mayor rendimiento en nuestros modelos.
  
## ü¶æ ENTRENAMIENTO Y TESTEO DE MODELOS  
  
Una vez preparado el dato para ser entrenado, me apoyo en herramientas comparadoras de modelos de *Machine Learning* tales como *Lazy* o H2O. Ambas herramientas concluyen lo mismo. Con los datos que manejamos el modelo que m√°s rendimiento alcanza es el modelo lineal *Huber Regressor* de la librer√≠a *SKLearn*.
  
A partir de este momento la labor consistir√° en hacer peque√±as modificaciones en los datos y su limpieza para intentar exprimir nuestro modelo al m√°ximo. Para el mismo fin, se ha hecho un trabajo de *Grid searching* para encontrar los par√°metros √≥ptimos de nuestro modelo.
  
## üìù CONCLUSIONES
  
Con la realizaci√≥n de este proyecto me doy cuenta de la existencia de un sin fin de modelos y herramientas a nuestro alcance para realizar predicciones. Sin embargo, considero que la parte m√°s fundamental del proceso es la limpieza, preparaci√≥n y etiquetaci√≥n del dato. Sin realizar de manera adecuada este proceso, nuestros modelos carecer√°n de la consistencia y fiabilidad necesaria para ser tomados como v√°lidos.
  
Por otro lado concluyo, que las iniciativas tales como la impulsora de este proyecto (competici√≥n de Kaggle), son una excelente manera para que los participantes aprendan, se desaf√≠en a s√≠ mismos, construyan su reputaci√≥n y ganen reconocimiento en el campo de la ciencia de datos.
