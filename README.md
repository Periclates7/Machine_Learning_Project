![Cabecera](https://github.com/Periclates7/Machine_Learning_Project/blob/main/img/brain%20lightning_3.jpg)

# üå≥ MACHINE LEARNING PROJECT -> PREDICTING SALARIES (KAGGLE COMPETITION) üèÜ  
  
El presente proyecto nace de la inscripci√≥n a la competici√≥n de Kaggle ["Predict the Salary for Data Science Jobs"](https://www.kaggle.com/competitions/predict-salary-for-data-science-jobs/). La competici√≥n se basa en el entrenamiento de modelos de *Machine Learning* para la predicci√≥n salarios en posiciones relativas a la ciencia de datos. Para ello se cuenta con tres archivos .csv. El primero para entrenar nuestros modelos, el segundo para testearlos y el tercero nos servir√° como herramienta para competir.
  
## üéØ OBJETIVOS DEL PROYECTO 
  
1. Crear un repositorio en GitHub con una buena organizaci√≥n de los recursos.
2. Extraer los datos de manera √≥ptima.
3. Aplicar herramientas, t√©cnicas y metodolog√≠as para la limpieza de datos acordes a nuestras necesidades:
    - Filtrado de los datos extraidos
    - Exploraci√≥n del conjunto de los datos
    - Limpieza de valores nulos
    - Transformaci√≥n de diferentes conjuntos de datos
    - Librer√≠as utilizadas: Pandas, Numpy, Pylab, Seaborn, Sklearn.
3. Analizar, Adecuar y codificar los datos para ser entrenados.
4. Aplicar modelos de *Machine Learning*.
5. Evaluar dichos modelos.
6. Hacer predicciones con nuestros modelos.
7. Exportar y cargar en Kaggle nuestras predicciones.
  
## ‚õè AN√ÅLISIS Y LIMPIEZA DE LOS DATOS  
  
Nos encontramos con un *dataset* que contiene el salario de diferentes posiciones en el √°mbito de la ciencia de datos seg√∫n varias variables tales como, el tipo de empleo, la posici√≥n, el pa√≠s o su nivel de experiencia entre otras. El conjunto de datos es un conjunto muy limpio, con los datos bastante consistentes pero inoperativos ya que la mayor√≠a de las columnas son categ√≥ricas. El gran reto de este proyecto ser√° el codificar dichas columnas de la manera m√°s acertada para que nuestros modelos puedan trabajar con el m√°ximo rendimiento. 
  
Esta transformaci√≥n parte de un an√°lisis exhaustivo de las columnas a transformar. En su mayor√≠a, intento determinar la relevancia de cada dato para codificarlo en base a su importancia. Esto nos crear√° un sesgo, s√≠, pero un sesgo basado en los datos. Por otro lado tambi√©n se prueban t√©cnicas de *one-hot-encoding* para aquellas columnas que no estaban tan claramente jerarquizadas.
  
Cabe destacar que el proceso de transformaci√≥n del dato se ha visto modificado a lo largo de la realizaci√≥n del proyecto con el fin de testear cuantas m√°s posibilidades y de esta manera conseguir el mayor rendimiento en nuestros modelos.
  
## ü¶æ ENTRENAMIENTO Y TESTEO DE MODELOS  
